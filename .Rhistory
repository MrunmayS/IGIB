docs1 = tm_map(docs, toSpace, "#")
docs1 = tm_map(docs1, content_transformer(tolower))
docs1 = tm_map(docs1, removeNumbers)
docs1 = tm_map(docs1, removeWords, stopwords("english"))
docs1 = tm_map(docs1, removeWords, data_common_words)
docs1 = tm_map(docs1, stripWhitespace)
dtm = TermDocumentMatrix(docs1)
m = as.matrix(dtm)
v = sort(rowSums(m),
decreasing = TRUE)
d = data.frame(word = names(v),
freq = v)
head(d, 10)
common_words = load("data_common_words.RData")
wordcloud(words = d$word,
freq = d$freq,
min.freq = 1,
max.words = 250,
random.order = FALSE,
rot.per = 0.35,
colors = brewer.pal(8, "Dark2"))
barplot(d[1:10, ]$freq, names.arg = d[1:10, ]$word,
col ="lightgreen", main ="Top 10 most frequent words",
ylab = "Word frequencies", xlab="Words")
makebarplot <- function(df)
{
library(ggplot2)
ggplot(data = df[1:10, ], aes(x=df[1:10,]$word, y=df[1:10,]$freq, fill=df[1:10, ]$word))+
geom_bar(position ='dodge', stat="identity")+
labs(fill="Words")+
ggtitle('Top 20 Most frequent words')+
xlab('Words')+
ylab('Frequency')
}
makebarplot(freqtable)
makebarplot <- function(df)
{
library(ggplot2)
ggplot(data = df[1:10, ], aes(x=df[1:10,]$word, y=df[1:10,]$freq, fill=df[1:10, ]$word))+
geom_bar(position ='dodge', stat="identity")+
labs(fill="Words")+
ggtitle('Top 10 Most frequent words')+
xlab('Words')+
ylab('Frequency')
}
makebarplot(freqtable)
makebarplot <- function(df)
{
library(ggplot2)
ggplot(data = df[1:20, ], aes(x=df[1:20,]$word, y=df[1:20,]$freq, fill=df[1:20, ]$word))+
geom_bar(position ='dodge', stat="identity")+
labs(fill="Words")+
ggtitle('Top 10 Most frequent words')+
xlab('Words')+
ylab('Frequency')
}
makebarplot(freqtable)
makebarplot <- function(df)
{
library(ggplot2)
ggplot(data = df[1:10, ], aes(x=df[1:10,]$word, y=df[1:10,]$freq, fill=df[1:10, ]$word))+
geom_bar(position ='dodge', stat="identity")+
labs(fill="Words")+
ggtitle('Top 10 Most frequent words')+
xlab('Words')+
ylab('Frequency')
}
makebarplot(freqtable)
makebarplot <- function(df)
{
library(ggplot2)
ggplot(data = df[1:10, ], aes(x=df[1:10,]$word, y=df[1:10,]$freq, fill=df[1:10, ]$word))+
geom_bar(position ='dodge', stat="identity")+
labs(fill="Words")+
ggtitle('Top 10 Most frequent words')+
xlab('Words')+
ylab('Frequency')
}
makebarplot(freqtable)
maketopicmodel <- function(x){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(corpus, toSpace, "@")
processedcorpus <- tm_map(corpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
K <- 10
topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
top_terms <- topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
}
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(corpus, toSpace, "@")
processedcorpus <- tm_map(corpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 25))
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
maketopicmodel <- function(x){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
K <- 10
topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
top_terms <- topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
}
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 25))
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
maketopicmodel(dfn$Abstract)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 25))
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
topics <- createtopics(dfn$Abstract, 20)
topics <- createtopics(dfn$Abstract, 10)
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
#topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 25))
topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500))
#topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 500, verbose = 5))
#topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="Gibbs")
#topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="VEM" , control=list(iter = 500, verbose = 25))
#topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
topics <- createtopics(dfn$Abstract, 20)
createtopics <- function(x, K){
corpus <- VCorpus(VectorSource(x))
# Text transformation
toSpace <- content_transformer(
function (x, pattern)
gsub(pattern, " ", x))
processedcorpus <- tm_map(corpus, toSpace, "/")
processedcorpus <- tm_map(processedcorpus, toSpace, "@")
processedcorpus <- tm_map(processedcorpus, toSpace, "#")
processedcorpus <- tm_map(processedcorpus, content_transformer(tolower))
processedcorpus <- tm_map(processedcorpus, removeNumbers)
processedcorpus <- tm_map(processedcorpus, removeWords, stopwords("english"))
processedcorpus <- tm_map(processedcorpus, removeWords, data_common_words)
processedcorpus <- tm_map(processedcorpus, stripWhitespace)
DTM <- DocumentTermMatrix(processedcorpus, control = list(bounds = list(global = c(5, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
topicModel <- LDA(DTM, K, method="VEM" )
#topicModel <- LDA(DTM, K)
tmResult <- posterior(topicModel)
attributes(tmResult)
nTerms(DTM)
betas <- tmResult$terms
dim(beta)
thetas <- tmResult$topics
rowSums(thetas)[1:10]
terms(topicModel, 10)
topics <- tidy(topicModel, matrix = "beta")
}
text_link <- function(topics){
my_adj_list <- topics %>% filter(beta > 0.025)
names(my_adj_list) <- c('from', 'to', 'weight')
class(my_adj_list)
dim(my_adj_list)
net <- graph.data.frame(my_adj_list, directed = FALSE)
orig_mar <- par()$mar
par(mar=rep(.1, 4))
plot(net, layout = layout_components(net), edge.width = E(net)$weight)
}
maketopicmodel(dfn$Abstract)
topics <- createtopics(dfn$Abstract, 20)
text_link(topics)
